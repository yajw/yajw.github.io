<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>blog -  2019-12-20 linux 实用命令</title><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/static/css/androidstudio.min.css"/><script src="/static/js/highlight.min.js"></script><script>hljs.highlightAll();</script><meta name="next-head-count" content="7"/><link rel="preload" href="/_next/static/css/3c5946e20da2cc20d075.css" as="style"/><link rel="stylesheet" href="/_next/static/css/3c5946e20da2cc20d075.css" data-n-g=""/><link rel="preload" href="/_next/static/css/e2e6dc732d39303ab748.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e2e6dc732d39303ab748.css" data-n-p=""/><link rel="preload" href="/_next/static/css/4b5ef9ffeb729d4f1c31.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4b5ef9ffeb729d4f1c31.css" data-n-p=""/><noscript data-n-css=""></noscript><link rel="preload" href="/_next/static/chunks/main-c006ee6087559bbd65e3.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-50bee04d1dc61f8adf5b.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.15878d4e523f86636251.js" as="script"/><link rel="preload" href="/_next/static/chunks/99f422a92ff7083adb8a7d840734144fa7589f68.e37cca09058b1656d546.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-86af5e0fcdd51c9c3a66.js" as="script"/><link rel="preload" href="/_next/static/chunks/314642ff.81d3755a1df95fed9f2f.js" as="script"/><link rel="preload" href="/_next/static/chunks/762e22088df2ca7ea97d3f731b2a7315c482f91e.cb9acb13aef2b3683e00.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/blog/%5Blink%5D-87cd50cf458654f0c030.js" as="script"/></head><body><div id="__next"><div class="Home_container__1EcsU"><main class="Home_main__1x8gC"><div class="ui text container"><h1 class="ui header"> 2019-12-20 linux 实用命令</h1><span></span><section><h2>sftp</h2>
<p>upload local file to remote sftp:</p>
<pre><code class="language-bash">sftp -oPort=2201 user@host:${remote_path} &#x3C;&#x3C;&#x3C; $'put {local_file_path}'
</code></pre>
<p>download remote file to local:</p>
<pre><code class="language-bash">sftp user@host:${remote_path} ${local_path}
</code></pre>
<p>路径支持通配符来匹配多个文件</p>
<p>sftp常用命令有这些：<code>ls</code> <code>ls -lh</code> <code>rm</code> <code>put</code> <code>get</code>等。</p>
<h2>split</h2>
<ul>
<li>mac安装gsplit: <code>brew install coreutils</code></li>
</ul>
<p>文件分割比较有用。例如把一个script.sql文件按每100行拆分，输出文件前缀为split_
mac上用的gsplit (GNU版本的split)</p>
<pre><code class="language-bash">gsplit -dl 400 --additional-suffix=.sql script.sql script_
</code></pre>
<p>也支持按文件大小分割，同时支持按行分割</p>
<pre><code class="language-bash">gsplit -C 10M --additional-suffix=.sql script.sql script_
</code></pre>
<h2>sed</h2>
<p>例如，script.sql文件每行一条insert语句，想要改成<code>on duplicate update</code>来同时支持插入和已有记录的更新（这个操作是幂等的），就可以用下面的方法：</p>
<p>第一步，去掉文件每行末的最后一个字符：</p>
<pre><code class="language-bash">sed 's/.$//' script.sql > script_noprefix.sql
</code></pre>
<p>然后，给每行加上指定字符串，这里是<code>ON DUPLICATE KEY</code>:</p>
<pre><code class="language-bash">sed 's/.$/ ON DUPLICATE KEY UPDATE update_time=values(update_time);/' script_noprefix.sql > script_update_insert.sql
</code></pre>
<p>sed支持直接替换，上面的例子也可以直接替最后一个字符为指定字符串。
一个替换的例子(mac版本)，<strong>注意：这里是原地替换，直接修改原文件内</strong>：</p>
<pre><code class="language-bash">sed -i '' -- 's/.$/ ON DUPLICATE KEY UPDATE update_time=values(update_time);/g' script.sql
</code></pre>
<h2>awk 实用套路</h2>
<p>其他学习文章</p>
<ul>
<li>AWK 简明教程 https://coolshell.cn/articles/9070.html</li>
<li>awk 入门教程 http://www.ruanyifeng.com/blog/2018/11/awk.html</li>
</ul>
<h3>匹配</h3>
<p><strong>包含某些关键词，但不包含其他关键词</strong></p>
<pre><code class="language-bash">awk -F '|' '/error|warn/ &#x26;&#x26; !/system/' error.log
</code></pre>
<h3>统计</h3>
<p><strong>日志第一列是ip，数不同ip的日志行数</strong></p>
<pre><code class="language-bash">awk -v OFS='\t' -F '|' '{count[$1]++;} END {for (ip in count) print ip, count[ip]}' info.log
</code></pre>
<p><strong>按照ip数统计某个url的请求量</strong></p>
<pre><code class="language-bash">awk -F '|' '/api\/service/ &#x26;&#x26; !/api\/service\/other/ {c[$1]++} END {for (ip in c) print ip,c[ip]}' info.log
</code></pre>
<p><strong>按照小时统计某个url的请求量</strong></p>
<p>sample log</p>
<pre><code>0.0.0.0|2019-12-19 13:01:02|elapsed=12ms,url=/api/service
</code></pre>
<pre><code class="language-bash">awk -F '|' '/api\/service/ {split($2, t, "[-: ]"); c[t[4]]++;} END {for (hour in c) print hour,c[hour]}' info.log | sort -k1
</code></pre>
<p><strong>按照小时统计某个url的请求量，并且包含占总量的百分比</strong></p>
<pre><code class="language-bash">awk -F '|' '/api\/service/ {split($2, t, "[-: ]"); c[t[4]]++; s++} END {for (hour in c) printf "%s\t%s\t%.2f\n" hour,c[hour],100*c[hour]/s}' info.log | sort -k1
</code></pre>
<p><strong>统计错误日志中不同类型的种类</strong></p>
<pre><code class="language-bash">awk -F '|' ' /ERROR/ {c[$7]++;s++} END {for (r in c) printf "%s\t%.2f\t%s\n", c[r],100*c[r]/s,r}' error.log | sort -k2
</code></pre>
<p><strong>连接状态统计</strong></p>
<pre><code class="language-bash">ss | awk 'NR!=1{c[$2]++} END {for (s in c) print s, c[s]}'
</code></pre>
<p><strong>统计不同目的ip的不同状态的连接数</strong></p>
<pre><code class="language-bash">netstat -t | awk -v OFS='\t\t' 'NR>2{c[$5,$6]++} END {for (x in c) {split(x, s, SUBSEP); print c[x],s[2],s[1]} }'
</code></pre>
<h3>远程awk重定向输出到本地文件</h3>
<p>这个需要在本地分析日志时很有用，heredoc可以避开escape的问题。</p>
<p>借助heredoc和ssh重定向</p>
<pre><code class="language-bash">ssh > daemon.log aps-live-log &#x3C;&#x3C;-'EOF'
awk -F '|' '!/ktc_settlement_report/ &#x26;&#x26; !/txn_3ds/ &#x26;&#x26; $2>"[2020-01-05 01:00:00" &#x26;&#x26; $2&#x3C;"[2020-01-05 01:05:00"' /data/error.log
EOF
</code></pre>
<h3>awk 正则匹配筛选比较耗时的请求</h3>
<p>正则匹配提取：</p>
<pre><code class="language-bash">awk -F'|' 'match($6, /elapsed=([0-9]+)/, ta) &#x26;&#x26; match($6, /id=([0-9]+)/, ka) {c[ka[1]]=ta[1]} END {for (k in c) {print t,c[t]}}' data.log | sort -n -k 2
</code></pre>
<p>数值比较（筛选出耗时超过2秒的请求）</p>
<pre><code class="language-bash"> awk -F'|' 'match($6, /elapsed=([0-9]+)/, ta) &#x26;&#x26; match($6, /id=([0-9]+)/, ka) {if ((ta[1]+0)>2000) c[ka[1]]=ta[1]} END {for (t in c) {print t,c[t]}}' data_log | sort -n -k 2
</code></pre>
<h3>ss</h3>
<p>mac 下模拟ss: <code>alias ss='lsof -Pn -i4 | grep LISTEN'</code></p>
<h3>ssh</h3>
<p>ssh 转发： https://jin-yang.github.io/post/ssh-proxy.html</p>
<h3>获取访问某个ip的本地接口</h3>
<p>outgoing ip</p>
<p>ip route get 8.8.8.8
mac: brew install iproute2mac</p>
</section><div role="list" class="ui list"><div role="listitem" class="item">2021-03-27 14:49:15 +0800<!-- --> <!-- -->yajw<!-- --> <!-- -->Copy old posts<!-- --> <!-- -->A</div></div><div id="comments"></div></div></main><footer class="Home_footer__1WdhD"><div class="Home_powered__2GdUA">Powered by<!-- --> <a href="https://nextjs.org/" target="_blank" rel="noopener noreferrer">Next.js</a>.</div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":" 2019-12-20 linux 实用命令","comments":true,"tags":["linux","awk","split","sed"],"categories":["实用"],"modifyTime":"2021-03-27 14:49:15 +0800","createTime":"2021-03-27 14:49:15 +0800","logs":[{"status":["A"],"files":["\"2021-03-27 2019-12-20 linux \\345\\256\\236\\347\\224\\250\\345\\221\\275\\344\\273\\244.md\""],"abbrevHash":"f4f4061","hash":"f4f406175bde5279c552d8bac1c05cf7bb72d58e","subject":"Copy old posts","authorName":"yajw","authorDate":"2021-03-27 14:49:15 +0800"}],"link":"2021-03-27%202019-12-20%20linux%20%E5%AE%9E%E7%94%A8%E5%91%BD%E4%BB%A4","id":"99ae7def-8551-4a5e-af12-1908a68c2aef","content":"\u003ch2\u003esftp\u003c/h2\u003e\n\u003cp\u003eupload local file to remote sftp:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003esftp -oPort=2201 user@host:${remote_path} \u0026#x3C;\u0026#x3C;\u0026#x3C; $'put {local_file_path}'\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003edownload remote file to local:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003esftp user@host:${remote_path} ${local_path}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e路径支持通配符来匹配多个文件\u003c/p\u003e\n\u003cp\u003esftp常用命令有这些：\u003ccode\u003els\u003c/code\u003e \u003ccode\u003els -lh\u003c/code\u003e \u003ccode\u003erm\u003c/code\u003e \u003ccode\u003eput\u003c/code\u003e \u003ccode\u003eget\u003c/code\u003e等。\u003c/p\u003e\n\u003ch2\u003esplit\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003emac安装gsplit: \u003ccode\u003ebrew install coreutils\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e文件分割比较有用。例如把一个script.sql文件按每100行拆分，输出文件前缀为split_\nmac上用的gsplit (GNU版本的split)\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003egsplit -dl 400 --additional-suffix=.sql script.sql script_\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e也支持按文件大小分割，同时支持按行分割\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003egsplit -C 10M --additional-suffix=.sql script.sql script_\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003esed\u003c/h2\u003e\n\u003cp\u003e例如，script.sql文件每行一条insert语句，想要改成\u003ccode\u003eon duplicate update\u003c/code\u003e来同时支持插入和已有记录的更新（这个操作是幂等的），就可以用下面的方法：\u003c/p\u003e\n\u003cp\u003e第一步，去掉文件每行末的最后一个字符：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003esed 's/.$//' script.sql \u003e script_noprefix.sql\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e然后，给每行加上指定字符串，这里是\u003ccode\u003eON DUPLICATE KEY\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003esed 's/.$/ ON DUPLICATE KEY UPDATE update_time=values(update_time);/' script_noprefix.sql \u003e script_update_insert.sql\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003esed支持直接替换，上面的例子也可以直接替最后一个字符为指定字符串。\n一个替换的例子(mac版本)，\u003cstrong\u003e注意：这里是原地替换，直接修改原文件内\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003esed -i '' -- 's/.$/ ON DUPLICATE KEY UPDATE update_time=values(update_time);/g' script.sql\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eawk 实用套路\u003c/h2\u003e\n\u003cp\u003e其他学习文章\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAWK 简明教程 https://coolshell.cn/articles/9070.html\u003c/li\u003e\n\u003cli\u003eawk 入门教程 http://www.ruanyifeng.com/blog/2018/11/awk.html\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e匹配\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e包含某些关键词，但不包含其他关键词\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eawk -F '|' '/error|warn/ \u0026#x26;\u0026#x26; !/system/' error.log\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e统计\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e日志第一列是ip，数不同ip的日志行数\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eawk -v OFS='\\t' -F '|' '{count[$1]++;} END {for (ip in count) print ip, count[ip]}' info.log\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e按照ip数统计某个url的请求量\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eawk -F '|' '/api\\/service/ \u0026#x26;\u0026#x26; !/api\\/service\\/other/ {c[$1]++} END {for (ip in c) print ip,c[ip]}' info.log\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e按照小时统计某个url的请求量\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003esample log\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e0.0.0.0|2019-12-19 13:01:02|elapsed=12ms,url=/api/service\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eawk -F '|' '/api\\/service/ {split($2, t, \"[-: ]\"); c[t[4]]++;} END {for (hour in c) print hour,c[hour]}' info.log | sort -k1\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e按照小时统计某个url的请求量，并且包含占总量的百分比\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eawk -F '|' '/api\\/service/ {split($2, t, \"[-: ]\"); c[t[4]]++; s++} END {for (hour in c) printf \"%s\\t%s\\t%.2f\\n\" hour,c[hour],100*c[hour]/s}' info.log | sort -k1\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e统计错误日志中不同类型的种类\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eawk -F '|' ' /ERROR/ {c[$7]++;s++} END {for (r in c) printf \"%s\\t%.2f\\t%s\\n\", c[r],100*c[r]/s,r}' error.log | sort -k2\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e连接状态统计\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003ess | awk 'NR!=1{c[$2]++} END {for (s in c) print s, c[s]}'\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e统计不同目的ip的不同状态的连接数\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003enetstat -t | awk -v OFS='\\t\\t' 'NR\u003e2{c[$5,$6]++} END {for (x in c) {split(x, s, SUBSEP); print c[x],s[2],s[1]} }'\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e远程awk重定向输出到本地文件\u003c/h3\u003e\n\u003cp\u003e这个需要在本地分析日志时很有用，heredoc可以避开escape的问题。\u003c/p\u003e\n\u003cp\u003e借助heredoc和ssh重定向\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003essh \u003e daemon.log aps-live-log \u0026#x3C;\u0026#x3C;-'EOF'\nawk -F '|' '!/ktc_settlement_report/ \u0026#x26;\u0026#x26; !/txn_3ds/ \u0026#x26;\u0026#x26; $2\u003e\"[2020-01-05 01:00:00\" \u0026#x26;\u0026#x26; $2\u0026#x3C;\"[2020-01-05 01:05:00\"' /data/error.log\nEOF\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eawk 正则匹配筛选比较耗时的请求\u003c/h3\u003e\n\u003cp\u003e正则匹配提取：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eawk -F'|' 'match($6, /elapsed=([0-9]+)/, ta) \u0026#x26;\u0026#x26; match($6, /id=([0-9]+)/, ka) {c[ka[1]]=ta[1]} END {for (k in c) {print t,c[t]}}' data.log | sort -n -k 2\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e数值比较（筛选出耗时超过2秒的请求）\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e awk -F'|' 'match($6, /elapsed=([0-9]+)/, ta) \u0026#x26;\u0026#x26; match($6, /id=([0-9]+)/, ka) {if ((ta[1]+0)\u003e2000) c[ka[1]]=ta[1]} END {for (t in c) {print t,c[t]}}' data_log | sort -n -k 2\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003ess\u003c/h3\u003e\n\u003cp\u003emac 下模拟ss: \u003ccode\u003ealias ss='lsof -Pn -i4 | grep LISTEN'\u003c/code\u003e\u003c/p\u003e\n\u003ch3\u003essh\u003c/h3\u003e\n\u003cp\u003essh 转发： https://jin-yang.github.io/post/ssh-proxy.html\u003c/p\u003e\n\u003ch3\u003e获取访问某个ip的本地接口\u003c/h3\u003e\n\u003cp\u003eoutgoing ip\u003c/p\u003e\n\u003cp\u003eip route get 8.8.8.8\nmac: brew install iproute2mac\u003c/p\u003e\n"}},"__N_SSG":true},"page":"/blog/[link]","query":{"link":"2021-03-27 2019-12-20 linux 实用命令"},"buildId":"ravzvVxRlFE3_IAU4jdd7","nextExport":false,"isFallback":false,"gsp":true}</script><script nomodule="" src="/_next/static/chunks/polyfills-ff94e68042added27a93.js"></script><script src="/_next/static/chunks/main-c006ee6087559bbd65e3.js" async=""></script><script src="/_next/static/chunks/webpack-50bee04d1dc61f8adf5b.js" async=""></script><script src="/_next/static/chunks/framework.15878d4e523f86636251.js" async=""></script><script src="/_next/static/chunks/99f422a92ff7083adb8a7d840734144fa7589f68.e37cca09058b1656d546.js" async=""></script><script src="/_next/static/chunks/pages/_app-86af5e0fcdd51c9c3a66.js" async=""></script><script src="/_next/static/chunks/314642ff.81d3755a1df95fed9f2f.js" async=""></script><script src="/_next/static/chunks/762e22088df2ca7ea97d3f731b2a7315c482f91e.cb9acb13aef2b3683e00.js" async=""></script><script src="/_next/static/chunks/pages/blog/%5Blink%5D-87cd50cf458654f0c030.js" async=""></script><script src="/_next/static/ravzvVxRlFE3_IAU4jdd7/_buildManifest.js" async=""></script><script src="/_next/static/ravzvVxRlFE3_IAU4jdd7/_ssgManifest.js" async=""></script></body></html>