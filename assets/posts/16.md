
这个ppt是2012年3月份，那时我大三下学期，刚好接触ACM吧。

很多大型系统都按照模块拆分成很多个后台服务，构成扇形结构（Fanout Services）。

这种结构下，一个顶层的请求会被拆分成很多对子系统的请求，这时就如水桶原理，整个请求的延时取决于最慢的那个。这里面是个概率分布问题，一个顶层请求分发给越多的机器，那么相应时间也就越可能变慢。假设单个机器的响应时间分布是独立的，考虑多台机器的相应时间的联合分布。

按照这个ppt所说，Google的机器是多个服务共享的，也就是一个机器可能部署很多个各种各样的服务。这个类似云计算的资源共享，能提升资源利用率，降低成本。但是对一个服务来说，这个环境的相应时间有些不可预测，因为需要去竞争有限的资源。那么云计算是如何解决资源调度的问题呢？这个问题等研究后再说。

相对于Fault Tolerating，这个ppt提出Variability Tolerating。Fault Tolerating是用多余的不可靠的组件来构建可靠的系统。variability Tolerating是用不可预测的部件来构造可预测的系统。提到了一些排队机制，精细地管理机器上的活动，更多是系统层面的。

下面才是干货，Latency Tolerating Techniques：
1. 服务层面的自适应
   - 收集相应指标，尽可能减少后面请求的延时
   - 具体措施，动态负载均衡机制，例如熔断器之类的
   - 分片：把服务分布在多台机器上
   - 有选择备份：对重要的或者热点加更多的备份
2. 请求层面的自适应，一些pattern
   - canary request: 尝试一个节点没问题，概率上对其他节点就有信心
   - backup requests：对付长尾效应，等2ms再发一个请求，并且在收到回复后取消另一个请求（降低资源消耗？）给出的数据还是蛮有说服力的。这里有个前提是请求要是幂等的。
   - 根据业务需求，tradeoff准确性和延迟

读后感：方法很多，更多地要靠实践，具体问题具体分析，用好的结果来回答怎么降低延迟的问题，这个ppt整体也是这样的思路。


